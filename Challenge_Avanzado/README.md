# Challenge Avanzado - Predicci√≥n de Precios de Acciones con PySpark y PyCaret

**Autor**: H√©ctor Gabriel S√°nchez P√©rez  
**Proyecto**: Challenge Avanzado - Maestr√≠a en Ciencia de Datos

---

## üìã Descripci√≥n General

Este proyecto presenta un **pipeline completo de Machine Learning** para **predicci√≥n de precios de acciones** utilizando datos financieros en tiempo real. Combina las capacidades de **PySpark** para procesamiento distribuido de grandes vol√∫menes de datos con **PyCaret** para modelado autom√°tico de aprendizaje autom√°tico.

### üéØ Objetivo Principal

Desarrollar un modelo predictivo robusto que pueda **anticipar el precio de cierre** de acciones de Microsoft (MSFT) bas√°ndose en datos hist√≥ricos intraday (minuto a minuto), utilizando t√©cnicas avanzas de:
- **Feature Engineering** con Window Functions de Spark
- **AutoML** con PyCaret para comparaci√≥n autom√°tica de m√∫ltiples algoritmos
- **An√°lisis de streaming** simulado para procesamiento de datos en tiempo real

---

## üîß Componentes Principales

### 1. **Adquisici√≥n de Datos**
- Descarga de datos financieros reales de MSFT usando la API de `yfinance`
- Rango temporal: 7 d√≠as con intervalo de 1 minuto
- Incluye variables de OHLCV (Open, High, Low, Close, Volume)

### 2. **Procesamiento Distribuido con PySpark**
- Conversi√≥n de datos a formato Spark para escalabilidad
- Persistencia en Databricks Serverless para reproducibilidad
- **Feature Engineering distribuido** usando Window Functions:
  - Promedios m√≥viles
  - Volatilidad calculada
  - Caracter√≠sticas t√©cnicas de series temporales

### 3. **An√°lisis Exploratorio de Datos (EDA)**
- Detecci√≥n de outliers y patrones an√≥malos
- An√°lisis de correlaciones entre variables
- Visualizaci√≥n de tendencias temporales
- Estad√≠sticas descriptivas completas

### 4. **Modelado Predictivo con PyCaret**
- Comparaci√≥n autom√°tica de **15+ algoritmos de regresi√≥n**
- Selecci√≥n del mejor modelo basado en m√©tricas de rendimiento
- Evaluaci√≥n exhaustiva con m√∫ltiples m√©tricas:
  - **R¬≤** (coeficiente de determinaci√≥n)
  - **RMSE** (Root Mean Squared Error)
  - **MAE** (Mean Absolute Error)
  - **MAPE** (Mean Absolute Percentage Error)

### 5. **Spark Streaming (Simulado)**
- Procesamiento en tiempo real con ventanas deslizantes
- Agregaciones temporales de 30 minutos con desplazamiento de 10 minutos
- Visualizaci√≥n de m√©tricas por ventanas de tiempo
- Simulaci√≥n de datos en streaming

### 6. **Evaluaci√≥n y Validaci√≥n**
- Gr√°ficas de diagn√≥stico (residuos, errores, importancia de features)
- An√°lisis de predicciones vs valores reales
- Interpretaci√≥n detallada de resultados
- Validaci√≥n cruzada del modelo

---

## üìä Estructura del Notebook

1. **Inicializaci√≥n de Spark Session en Databricks**
   - Conexi√≥n a Databricks Serverless
   - Manejo de errores y reconexi√≥n autom√°tica

2. **Carga y Exploraci√≥n de Datos**
   - Descarga de MSFT con yfinance
   - Conversi√≥n a Spark DataFrame
   - EDA inicial

3. **Feature Engineering**
   - Creaci√≥n de caracter√≠sticas con Window Functions
   - Ingenier√≠a de caracter√≠sticas t√©cnicas
   - Selecci√≥n de features relevantes

4. **Preparaci√≥n para Modelado**
   - Limpieza de datos faltantes
   - Normalizaci√≥n de variables
   - Divisi√≥n train-test

5. **AutoML con PyCaret**
   - Setup de regresi√≥n
   - Comparaci√≥n de modelos
   - Selecci√≥n del mejor modelo
   - Tuning de hiperpar√°metros

6. **An√°lisis de Streaming**
   - Simulaci√≥n de datos en tiempo real
   - Agregaciones por ventanas temporales
   - M√©tricas de desempe√±o en l√≠nea

7. **Conclusiones y Resultados**
   - Resumen de hallazgos
   - Interpretaci√≥n del modelo
   - Recomendaciones pr√°cticas

---

## üöÄ Requisitos T√©cnicos

### Dependencias Python
```
pyspark>=3.0.0
pycaret>=2.3.0
yfinance>=0.2.0
pandas>=1.3.0
numpy>=1.21.0
matplotlib>=3.4.0
seaborn>=0.11.0
databricks-connect>=11.0.0 (si usas localmente)
```

### Plataforma
- **Databricks Serverless** (recomendado)
- O Python 3.8+ con Spark instalado localmente

---

## üìà Aplicaci√≥n Pr√°ctica

Este notebook es relevante para:

- **Trading Algor√≠tmico**: Predicci√≥n de precios para decisiones autom√°ticas de compra/venta
- **Gesti√≥n de Riesgo**: Monitoreo de volatilidad y tendencias de mercado
- **An√°lisis Cuantitativo**: Identificaci√≥n de patrones en series temporales financieras
- **Big Data en Finanzas**: Procesamiento escalable de grandes vol√∫menes de datos de mercado
- **Risk Management**: C√°lculo de exposici√≥n a volatilidad

---

## üéì Conceptos Clave Implementados

### Machine Learning
- **Regresi√≥n supervisada** para predicci√≥n continua
- **Cross-validation** para evaluaci√≥n robusta
- **Feature importance** para interpretabilidad
- **AutoML** para selecci√≥n autom√°tica de algoritmos

### Big Data
- **Spark DataFrames** para procesamiento distribuido
- **Window Functions** para c√°lculos temporales
- **Streaming** para procesamiento en tiempo real

### Finanzas
- **An√°lisis t√©cnico** (promedios m√≥viles, volatilidad)
- **Series temporales** con estructura OHLCV
- **An√°lisis intraday** con granularidad de minuto

---

## üìù Notas de Ejecuci√≥n

### En Databricks
1. Crea un cluster en Databricks
2. Adjunta este notebook al cluster
3. Ejecuta las celdas secuencialmente
4. La sesi√≥n Spark estar√° disponible autom√°ticamente

### Localmente con databricks-connect
1. Instala `databricks-connect`
2. Configura `~/.databrickscfg` con credenciales
3. Ejecuta el notebook (la primera celda establece la conexi√≥n)

### Consideraciones de Performance
- El procesamiento de datos est√° optimizado para clusters de Databricks
- Los Window Functions de Spark se paralelizar√°n autom√°ticamente
- PyCaret comparar√° m√∫ltiples algoritmos (puede tomar 5-15 minutos)

---

## üìä Salidas Esperadas

El notebook genera:
- **Modelos entrenados** con m√©tricas de desempe√±o
- **Visualizaciones** de EDA y diagn√≥sticos
- **Predicciones** sobre datos de test
- **An√°lisis de importancia de features**
- **Reporte completo** de resultados

---

## üîó Referencias

- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)
- [PyCaret Documentation](https://pycaret.org/)
- [Databricks Connect](https://docs.databricks.com/en/dev-tools/databricks-connect/index.html)
- [yfinance Documentation](https://github.com/ranaroussi/yfinance)

---

## üìÑ Archivos en la Carpeta

- `Challenge_Avanzado_Pycaret2.ipynb` - Notebook principal del proyecto
- `Challenge_Avanzado_Descripcion.md` - Descripci√≥n detallada adicional
- `pyproject.toml` - Configuraci√≥n de dependencias del proyecto
- `README.md` - Este archivo

---

## ‚úÖ Estatus del Proyecto

**Fase**: Completo  
**√öltima actualizaci√≥n**: Noviembre 2025  
**Autor**: Hector Gabriel S√°nchez P√©rez

---

## üìß Contacto

Para preguntas o comentarios sobre este proyecto, por favor contacta al autor.

---

*Este proyecto es parte del programa de **Maestr√≠a en Ciencia de Datos** y demuestra la aplicaci√≥n pr√°ctica de tecnolog√≠as modernas (Databricks Serverless, PySpark, AutoML) a problemas reales del mundo financiero.*
